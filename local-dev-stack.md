# Local Dev Stack

The local dev story is an important one to consider for this case study. The local development environment is the first line of defense for an IT organization. Logic defects, performance issues, database queries, and more can be tested locally. When developers can capture that story on their machines and work with local services and resources to troubleshoot and solution, it tightens feedback loops thus improving velocity. Developers need to rapidly iterate in multiple cycles to experiment, discover, and solution effectively. 

Today the local dev environment is tied to a remote shared postgres database. While this is a fine starting point, especially for small teams and startups, it can have massive scaling issues when it comes to data consistency and development. For example, developers will have a harder time building idempotent end-to-end tests since the data will be hard to predict. Developers will face challenges modifying the database model, which is frequent in greenfield contexts.

The proposed solution is to replicate the postgres database locally, just as we do with the api and frontend. To do this, we make use of docker and docker compose to codify a deployment manifest. This manifest is repeatable from a fresh environment on any MacOS, Windows, or Linux machine. The only prerequisite install is docker (docker-compose now comes pre-packaged with docker). From there, a user can run the [up script](./scripts/backend.sh) to spin up a compose stack that's comprised of a bun api server and a postgres database. [Migrations](./db/schema.sql) are run against the postgres container to initialize schemas and seed some initial data. The stack takes a few minutes to spin up with no cached images, and from there usually only takes a few seconds for rebuilds. This gives developers an environment they can quickly and repeatably stand up. If they need to develop models, they can do so without fear of stepping on others' toes. Furthermore, they can rapidly iterate and test against their local environment, and get a confident sense that they've built a code-complete feature.

However, we're just getting started. The real magic is in the [test script](./scripts/test.sh). This is an integration script that spins up the compose stack, waits for the api to come alive and respond to `/status`. It then runs the [bun test suite](./api/test/cars.test.ts) against the stack. This test suite runs api request tests calling the live server with a programmatically real postgres instance. This particular test calls GET on the `/cars` route, which will run a sql query to get all cars. The beauty of this is we have a way to automate end-to-end tests that execute database functions, using local database infrastructure and predictable data.

The next evolution of this is running this test suite in a pipeline. Since it's a docker compose stack, it can be run anywhere that docker is installed. Indeed, you can even install docker inside a docker container, meaning we can leverage containerized CI/CD platforms like [Github ARC](https://github.com/actions/actions-runner-controller), [Azure Devops](https://azure.microsoft.com/en-us/products/devops), and [Travis CI](https://www.travis-ci.com/) to run this test suite. We can automate powerfully informative tests during our CI process. Capturing query/database bugs early in the devops cycle dramatically reduces the chances of those issues reaching production and empowers devs to control their software with confidence. There should be no mysteries in how our system works, and test suites like this tell a powerful story that translates directly to improved product quality and developer satisfaction.